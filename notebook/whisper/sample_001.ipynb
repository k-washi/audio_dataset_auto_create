{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Whisperの動作確認"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_DIR = \"./data/speakers/aqua\"\n",
    "RAW_DATASET_DIR = f\"{DATASET_DIR}/raw\"\n",
    "SPLIT_AUDIO_DIR = f\"{DATASET_DIR}/split_audio\"\n",
    "SPLIT_TEXT_DIR = f\"{DATASET_DIR}/split_text\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/workspace\n",
      "/workspace\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "if Path(os.getcwd()).stem == \"whisper\":\n",
    "    %cd ../../\n",
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import whisper\n",
    "import math\n",
    "import numpy as np\n",
    "import torch\n",
    "import torchaudio\n",
    "from dataclasses import dataclass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.whisper.stable_whisper import (\n",
    "    modify_model,\n",
    "    stabilize_timestamps\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "WHISPER_MODEL = \"large\"\n",
    "WHISPER_LANG = \"ja\"\n",
    "model = whisper.load_model(WHISPER_MODEL, \"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "modify_model(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "59\n"
     ]
    }
   ],
   "source": [
    "dataset_dir = Path(RAW_DATASET_DIR)\n",
    "fp_list = list(dataset_dir.glob(\"*.wav\")) + list(dataset_dir.glob(\"*.mp3\"))\n",
    "fp_list = sorted(fp_list)\n",
    "print(len(fp_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class AudioData():\n",
    "    audio: np.ndarray\n",
    "    sr: int\n",
    "    \n",
    "    def save_audio(self, fp):\n",
    "        torchaudio.save(str(fp), torch.Tensor(self.audio).unsqueeze(0), self.sr)\n",
    "    \n",
    "    @classmethod\n",
    "    def pick_audio(cls, audio, start_time, end_time):\n",
    "        start_ind = max(0, math.floor(audio.sr*start_time))\n",
    "        end_ind = min(len(audio.audio), math.ceil(audio.sr*end_time))\n",
    "        return cls(\n",
    "            audio.audio[start_ind:end_ind],\n",
    "            audio.sr\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class SegmentAudio():\n",
    "    id: int\n",
    "    audio: AudioData\n",
    "    text: str\n",
    "    start: float\n",
    "    end: float\n",
    "    stop: False\n",
    "    \n",
    "    def save_text(self, fp):\n",
    "        with open(str(fp), \"w\") as f:\n",
    "            f.write(self.text)\n",
    "            \n",
    "    @classmethod\n",
    "    def from_whisper_result(cls, segment_dic):\n",
    "        \"\"\"whisperの検出結果から音声を抽出\"\"\"\n",
    "        id = segment_dic[\"id\"]\n",
    "        start = segment_dic[\"start\"]\n",
    "        end = segment_dic[\"end\"]\n",
    "        text = segment_dic[\"text\"]\n",
    "        #split_audio = audio.pick_audio(start, end)\n",
    "        stop = False\n",
    "        stop_word_list = (\"。\", \"?\", \"!\")\n",
    "        for stop_word in stop_word_list:\n",
    "            if len(stop_word) < len(text) and stop_word == text[-len(stop_word):]:\n",
    "                stop = True\n",
    "        return cls(\n",
    "            id,\n",
    "            AudioData(np.array([]), 0),\n",
    "            text,\n",
    "            start,\n",
    "            end,\n",
    "            stop\n",
    "        )\n",
    "    def update_pick_audio(self, audio: AudioData, end_time_room=0.005):\n",
    "        \"\"\"whisperの検出結果から音声を抽出\"\"\"\n",
    "        \n",
    "        self.audio = AudioData.pick_audio(audio, self.start, self.end+end_time_room)\n",
    "    \n",
    "    def is_error(self):\n",
    "        if self.start == self.end:\n",
    "            return True\n",
    "    \n",
    "    def skip(self, skip_time=0.5):\n",
    "        if self.end - self.start < skip_time:\n",
    "            return True\n",
    "        return False\n",
    "    \n",
    "    def is_continuos_segment(self, segment, continuos_time=0.3):\n",
    "        if self.stop:\n",
    "            return False\n",
    "        \n",
    "        if self.end + continuos_time < segment.start:\n",
    "            return True\n",
    "        return False\n",
    "    \n",
    "    def merge_segment(self, segment):\n",
    "        if not self.is_continuos_segment(segment):\n",
    "            raise ValueError(f\"連続したセグメントではありません。\")\n",
    "        self.text += segment.text\n",
    "        self.end = segment.end\n",
    "        self.stop = segment.stop\n",
    "        \n",
    "    def __repr__(self):\n",
    "        return f\"ID:{self.id:05d} {self.start:3f}-{self.end:3f}: {self.text}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/speakers/aqua/raw/10時ですけど.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/workspace/src/whisper/stable_whisper.py:987: UserWarning: A resampled input causes an unexplained temporal shift in waveform image that will skew the timestamp suppression and may result in inaccurate timestamps.\n",
      "Use audio_for_mask for transcribe() to provide the original audio track as the path or bytes of the audio file.\n",
      "  wf = _load_audio_waveform(audio_for_mask or audio, 100, int(mel.shape[-1] * ts_scale))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# [ID:00000 0.960000-2.240000: 十時ですけど…, ID:00001 2.240000-3.280000: ご主人、何してるんですか?]\n",
      "data/speakers/aqua/raw/11時〜….wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/workspace/src/whisper/stable_whisper.py:987: UserWarning: A resampled input causes an unexplained temporal shift in waveform image that will skew the timestamp suppression and may result in inaccurate timestamps.\n",
      "Use audio_for_mask for transcribe() to provide the original audio track as the path or bytes of the audio file.\n",
      "  wf = _load_audio_waveform(audio_for_mask or audio, 100, int(mel.shape[-1] * ts_scale))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# [ID:00000 0.000000-5.620000: 11時お腹すいたよご主人]\n",
      "data/speakers/aqua/raw/12時！.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/workspace/src/whisper/stable_whisper.py:987: UserWarning: A resampled input causes an unexplained temporal shift in waveform image that will skew the timestamp suppression and may result in inaccurate timestamps.\n",
      "Use audio_for_mask for transcribe() to provide the original audio track as the path or bytes of the audio file.\n",
      "  wf = _load_audio_waveform(audio_for_mask or audio, 100, int(mel.shape[-1] * ts_scale))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# [ID:00000 0.800000-6.000000: 12時お昼〜ご飯ご飯ご主人, ID:00004 6.000000-7.000000: ご飯まだ〜?]\n",
      "data/speakers/aqua/raw/13時です！.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/workspace/src/whisper/stable_whisper.py:987: UserWarning: A resampled input causes an unexplained temporal shift in waveform image that will skew the timestamp suppression and may result in inaccurate timestamps.\n",
      "Use audio_for_mask for transcribe() to provide the original audio track as the path or bytes of the audio file.\n",
      "  wf = _load_audio_waveform(audio_for_mask or audio, 100, int(mel.shape[-1] * ts_scale))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# [ID:00000 0.980000-2.980000: 13時です, ID:00001 2.980000-4.980000: 昼からも頑張っていきましょうね]\n",
      "data/speakers/aqua/raw/14時.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/workspace/src/whisper/stable_whisper.py:987: UserWarning: A resampled input causes an unexplained temporal shift in waveform image that will skew the timestamp suppression and may result in inaccurate timestamps.\n",
      "Use audio_for_mask for transcribe() to provide the original audio track as the path or bytes of the audio file.\n",
      "  wf = _load_audio_waveform(audio_for_mask or audio, 100, int(mel.shape[-1] * ts_scale))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# [ID:00000 0.640000-2.440000: 14時…, ID:00001 2.440000-4.120000: ふぅ…, ID:00002 4.120000-5.060000: なんだかお昼寝したくなってきた…]\n",
      "data/speakers/aqua/raw/15時です.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/workspace/src/whisper/stable_whisper.py:987: UserWarning: A resampled input causes an unexplained temporal shift in waveform image that will skew the timestamp suppression and may result in inaccurate timestamps.\n",
      "Use audio_for_mask for transcribe() to provide the original audio track as the path or bytes of the audio file.\n",
      "  wf = _load_audio_waveform(audio_for_mask or audio, 100, int(mel.shape[-1] * ts_scale))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# [ID:00000 0.800000-2.480000: 15時です。, ID:00001 2.480000-5.280000: ご主人様、そろそろお茶にしませんか?]\n",
      "data/speakers/aqua/raw/16時！.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/workspace/src/whisper/stable_whisper.py:987: UserWarning: A resampled input causes an unexplained temporal shift in waveform image that will skew the timestamp suppression and may result in inaccurate timestamps.\n",
      "Use audio_for_mask for transcribe() to provide the original audio track as the path or bytes of the audio file.\n",
      "  wf = _load_audio_waveform(audio_for_mask or audio, 100, int(mel.shape[-1] * ts_scale))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# [ID:00000 0.640000-1.320000: 16時!, ID:00001 1.320000-1.340000: ゲームしてたらいつの間にかこんな時間に]\n",
      "data/speakers/aqua/raw/17時ですよ.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/workspace/src/whisper/stable_whisper.py:987: UserWarning: A resampled input causes an unexplained temporal shift in waveform image that will skew the timestamp suppression and may result in inaccurate timestamps.\n",
      "Use audio_for_mask for transcribe() to provide the original audio track as the path or bytes of the audio file.\n",
      "  wf = _load_audio_waveform(audio_for_mask or audio, 100, int(mel.shape[-1] * ts_scale))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# [ID:00000 0.680000-2.520000: 17時ですよご主人, ID:00001 2.520000-4.520000: 今日のご飯は何かな?]\n",
      "data/speakers/aqua/raw/18時です.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/workspace/src/whisper/stable_whisper.py:987: UserWarning: A resampled input causes an unexplained temporal shift in waveform image that will skew the timestamp suppression and may result in inaccurate timestamps.\n",
      "Use audio_for_mask for transcribe() to provide the original audio track as the path or bytes of the audio file.\n",
      "  wf = _load_audio_waveform(audio_for_mask or audio, 100, int(mel.shape[-1] * ts_scale))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# [ID:00000 0.640000-2.160000: 18時です、ご主人!, ID:00001 2.160000-3.300000: 今日、寿司が食べたいです。]\n",
      "data/speakers/aqua/raw/19時になりました！.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/workspace/src/whisper/stable_whisper.py:987: UserWarning: A resampled input causes an unexplained temporal shift in waveform image that will skew the timestamp suppression and may result in inaccurate timestamps.\n",
      "Use audio_for_mask for transcribe() to provide the original audio track as the path or bytes of the audio file.\n",
      "  wf = _load_audio_waveform(audio_for_mask or audio, 100, int(mel.shape[-1] * ts_scale))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# [ID:00000 0.000000-5.300000: 19時になりました。ご主人、遊んでください!]\n",
      "data/speakers/aqua/raw/1時ですよ.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/workspace/src/whisper/stable_whisper.py:987: UserWarning: A resampled input causes an unexplained temporal shift in waveform image that will skew the timestamp suppression and may result in inaccurate timestamps.\n",
      "Use audio_for_mask for transcribe() to provide the original audio track as the path or bytes of the audio file.\n",
      "  wf = _load_audio_waveform(audio_for_mask or audio, 100, int(mel.shape[-1] * ts_scale))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# [ID:00000 1.040000-3.060000: 一時ですよご主人, ID:00001 3.060000-3.080000: まだまだ夜はこれからですね]\n",
      "data/speakers/aqua/raw/20時！.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/workspace/src/whisper/stable_whisper.py:987: UserWarning: A resampled input causes an unexplained temporal shift in waveform image that will skew the timestamp suppression and may result in inaccurate timestamps.\n",
      "Use audio_for_mask for transcribe() to provide the original audio track as the path or bytes of the audio file.\n",
      "  wf = _load_audio_waveform(audio_for_mask or audio, 100, int(mel.shape[-1] * ts_scale))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# [ID:00000 0.400000-2.400000: 二十時!, ID:00001 2.400000-2.900000: ご主人、今何考えてました?]\n",
      "data/speakers/aqua/raw/21時.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/workspace/src/whisper/stable_whisper.py:987: UserWarning: A resampled input causes an unexplained temporal shift in waveform image that will skew the timestamp suppression and may result in inaccurate timestamps.\n",
      "Use audio_for_mask for transcribe() to provide the original audio track as the path or bytes of the audio file.\n",
      "  wf = _load_audio_waveform(audio_for_mask or audio, 100, int(mel.shape[-1] * ts_scale))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# [ID:00000 0.880000-4.880000: 21時もうすぐ1日が終わっちゃう, ID:00002 4.880000-5.880000: やることちゃんと終わった?]\n",
      "data/speakers/aqua/raw/22時です。.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/workspace/src/whisper/stable_whisper.py:987: UserWarning: A resampled input causes an unexplained temporal shift in waveform image that will skew the timestamp suppression and may result in inaccurate timestamps.\n",
      "Use audio_for_mask for transcribe() to provide the original audio track as the path or bytes of the audio file.\n",
      "  wf = _load_audio_waveform(audio_for_mask or audio, 100, int(mel.shape[-1] * ts_scale))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# [ID:00000 0.560000-5.560000: 22時ですご主人様眠れないなら, ID:00003 5.560000-6.560000: それでも, ID:00004 6.560000-7.960000: 眠れして差し上げますよ]\n",
      "data/speakers/aqua/raw/23時だよ！.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/workspace/src/whisper/stable_whisper.py:987: UserWarning: A resampled input causes an unexplained temporal shift in waveform image that will skew the timestamp suppression and may result in inaccurate timestamps.\n",
      "Use audio_for_mask for transcribe() to provide the original audio track as the path or bytes of the audio file.\n",
      "  wf = _load_audio_waveform(audio_for_mask or audio, 100, int(mel.shape[-1] * ts_scale))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# [ID:00000 0.560000-2.480000: 23時だよ!, ID:00001 2.480000-4.320000: ご主人ゲームしよ!]\n"
     ]
    }
   ],
   "source": [
    "def transcribe(model: whisper, fp, lang=\"ja\"):\n",
    "    fp = Path(fp)\n",
    "    if not fp.is_file():\n",
    "        raise FileExistsError(f\"{fp}は、存在しません。\")\n",
    "    audio = whisper.load_audio(str(fp))\n",
    "    audio = whisper.pad_or_trim(audio)   \n",
    "    res = model.transcribe(audio, language=lang,  verbose=False)\n",
    "    segment_result = stabilize_timestamps(res, top_focus=True)\n",
    "    raw_audio = AudioData(audio, whisper.audio.SAMPLE_RATE)\n",
    "    segment_list = []\n",
    "    for seg in segment_result:\n",
    "        seg = SegmentAudio.from_whisper_result(seg)\n",
    "        if len(segment_list) == 0:\n",
    "            segment_list.append(\n",
    "                seg\n",
    "            )\n",
    "            continue\n",
    "        if segment_list[-1].is_continuos_segment(seg):\n",
    "            segment_list[-1].merge_segment(seg)\n",
    "        else:\n",
    "            segment_list.append(seg)\n",
    "    output_list = []\n",
    "    for o in segment_list:\n",
    "        o.update_pick_audio(raw_audio)\n",
    "        output_list.append(o)\n",
    "    return output_list\n",
    "\n",
    "count = 0\n",
    "for fp in fp_list[:15]:\n",
    "    print(fp)\n",
    "    output_list = transcribe(model, fp, lang=WHISPER_LANG)\n",
    "    print(\"#\", output_list)\n",
    "    for o in output_list:\n",
    "        count += 1\n",
    "        o.save_text(f\"{SPLIT_TEXT_DIR}/{count:010d}.txt\")\n",
    "        o.audio.save_audio(f\"{SPLIT_AUDIO_DIR}/{count:010d}.wav\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.7 ('.venv': poetry)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a2e3f7563a2d3ca1e59cb926cab9e9e65ee820741673d8365ead01571994f6b1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
